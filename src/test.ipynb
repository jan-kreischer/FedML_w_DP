{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068f289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import FEMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ca1f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init femnist\n",
      "Starting To Load Training Data\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-9.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-5.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-4.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-8.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-3.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-2.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-1.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-10.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-7.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-6.json' mode='r' encoding='UTF-8'>\n",
      "214443\n",
      "214443\n",
      "Finished Loading Training Data\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/test/femnist-5.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/test/femnist-4.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/test/femnist-3.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/test/femnist-2.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/test/femnist-1.json' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "femnist = FEMNIST(nr_clients=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61b18f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x16491baf0>, 71481)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femnist.get_client_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709d4ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x16664c5e0>,\n",
       " {0: 71481, 1: 71481, 2: 71481})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femnist.get_server_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ff7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92be868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset, Subset\n",
    "\n",
    "#data_train_split = Dict[float, torch.utils.data.Subset]\n",
    "data_train_split = {}\n",
    "ys = np.arange(10)\n",
    "Xs = np.linspace((1,2),(10,20),10)\n",
    "y_train_tensor = torch.Tensor(ys)\n",
    "X_train_tensor = torch.Tensor(Xs)\n",
    "client_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "client_subset = torch.utils.data.Subset(client_dataset, indices=np.arange(len(client_dataset)))\n",
    "client_id = 1\n",
    "data_train_split[0] = client_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee155bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init femnist\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/test/femnist-5.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/test/femnist-4.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/test/femnist-3.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/test/femnist-2.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/test/femnist-1.json' mode='r' encoding='UTF-8'>\n",
      "157304\n",
      "157304\n"
     ]
    }
   ],
   "source": [
    "print(\"init femnist\")\n",
    "import json\n",
    "import os,json\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset, Subset\n",
    "\n",
    "\n",
    "testing_data_path = './data/FEMNIST/test/'\n",
    "\n",
    "client_id = 0\n",
    "X_train_tensor = None\n",
    "y_train_tensor = None\n",
    "ys = []\n",
    "Xs = []\n",
    "for file_name in [file for file in os.listdir(testing_data_path) if file.endswith('.json')]:      \n",
    "    with open(testing_data_path + file_name) as f_test:\n",
    "        print(f_test)\n",
    "        test_dataset = json.load(f_test)\n",
    "        for user_id, user_data in test_dataset[\"user_data\"].items():\n",
    "            ys +=user_data[\"y\"]\n",
    "            Xs +=user_data[\"x\"]\n",
    "            #print(user_data[\"x\"])\n",
    "print(len(ys))\n",
    "print(len(Xs))\n",
    "y_train_tensor = torch.Tensor(ys)\n",
    "X_train_tensor = torch.Tensor(Xs)\n",
    "client_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "client_subset = torch.utils.data.Subset(client_dataset, indices=np.arange(len(client_dataset)))\n",
    "            #self.data_train_split[client_id] = client_subset\n",
    "            #client_id=client_id + 1\n",
    "            #print(\"preparing data for client {}\".format(client_id))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8f0ddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init femnist\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-9.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-5.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-4.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-8.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-3.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-2.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-1.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-10.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-7.json' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='./data/FEMNIST/train/femnist-6.json' mode='r' encoding='UTF-8'>\n",
      "214443\n",
      "214443\n"
     ]
    }
   ],
   "source": [
    "print(\"init femnist\")\n",
    "import json\n",
    "import os,json\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset, Subset\n",
    "\n",
    "\n",
    "\n",
    "client_id = 0\n",
    "X_train_tensor = None\n",
    "y_train_tensor = None\n",
    "ys = []\n",
    "Xs = []\n",
    "data_path = './data/FEMNIST/train/'\n",
    "for file_name in [file for file in os.listdir(training_data_path) if file.endswith('.json')]:\n",
    "    with open(data_path + file_name) as f:\n",
    "        print(f)\n",
    "        dataset = json.load(f)\n",
    "        for user_id, user_data in dataset[\"user_data\"].items():\n",
    "            #print(user_id)\n",
    "            ys +=user_data[\"y\"]\n",
    "            Xs +=user_data[\"x\"]\n",
    "\n",
    "print(len(ys))\n",
    "print(len(Xs))\n",
    "\n",
    "#y_train_tensor = torch.Tensor(ys)\n",
    "#X_train_tensor = torch.Tensor(Xs)\n",
    "#client_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "#client_subset = torch.utils.data.Subset(client_dataset, indices=np.arange(len(client_dataset)))\n",
    "            #self.data_train_split[client_id] = client_subset\n",
    "            #client_id=client_id + 1\n",
    "            #print(\"preparing data for client {}\".format(client_id))\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064013d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl_opt4ml",
   "language": "python",
   "name": "epfl_opt4ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
